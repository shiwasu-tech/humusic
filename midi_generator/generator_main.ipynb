{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初期設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ライブラリのimport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from miditok import REMI, TokenizerConfig\n",
    "from miditok.pytorch_data import DatasetMIDI, DataCollator\n",
    "from miditok.utils import split_files_for_training\n",
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import time\n",
    "import icecream as ic\n",
    "import os\n",
    "from symusic import Score\n",
    "import datetime\n",
    "\n",
    "import json\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deviceの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#device setting\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットとトークナイザーの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows piano1_only\n"
     ]
    }
   ],
   "source": [
    "platform_name = platform.system()\n",
    "dataset_name = \"piano1_only\"\n",
    "print(platform_name, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tokenizrの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keisu\\AppData\\Roaming\\Python\\Python39\\site-packages\\miditok\\tokenizations\\remi.py:77: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    }
   ],
   "source": [
    "# Creating a multitrack tokenizer, read the doc to explore all the parameters\n",
    "config = TokenizerConfig(num_velocities=16, use_chords=True, use_programs=True)\n",
    "tokenizer = REMI(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSONファイルを読み込む\n",
    "with open(\"../datasets/datasets_path.json\", \"r\", encoding=\"utf-8\") as json_file:\n",
    "    loaded_paths = json.load(json_file)[platform_name][dataset_name]\n",
    "\n",
    "\n",
    "# パスを取得\n",
    "dataset_dir = Path(loaded_paths[\"dataset_dir\"])\n",
    "files_paths = list(dataset_dir.glob(\"**/*.mid\"))\n",
    "tokenizer_path = Path(loaded_paths[\"tokenizer_path\"])\n",
    "chunks_dir = Path(loaded_paths[\"chunks_dir\"])\n",
    "#directory_path = Path(loaded_paths[\"directory_path\"])\n",
    "\n",
    "print(dataset_dir, \"\\n\", tokenizer_path, \"\\n\", chunks_dir)\n",
    "#print(f\"Directory path: {directory_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizerの作成とデータセットの分割（新規データのみ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer.train(vocab_size=30000, files_paths=files_paths)\n",
    "\n",
    "split_files_for_training(\n",
    "    files_paths=files_paths,\n",
    "    tokenizer=tokenizer,\n",
    "    save_dir=chunks_dir,\n",
    "    max_seq_len=1024,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = REMI(params=Path(\"tokens/maestro_token/tokenizer.json\"))\n",
    "\n",
    "# Create a Dataset, a DataLoader and a collator to train a model\n",
    "dataset = DatasetMIDI(\n",
    "    files_paths=list(chunks_dir.glob(\"**/*.mid\")),\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id, copy_inputs_as_labels=True)\n",
    "dataloader = DataLoader(dataset, batch_size=16, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mac環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the tokenizer with Byte Pair Encoding (BPE)\n",
    "#files_paths = list(Path(\"../datasets\").glob(\"**/*.mid\"))\n",
    "dataset_dir = Path(\"/Users/hapticslab/Programming/humusic/datasets/orchestra\")\n",
    "#dataset_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/datasets/orchestra\")\n",
    "#dataset_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/datasets/piano1_only\")\n",
    "files_paths = list(dataset_dir.glob(\"**/*.mid\"))\n",
    "\n",
    "tokenizer.train(vocab_size=30000, files_paths=files_paths)\n",
    "\n",
    "#tokenizer.save(Path(\"path\", \"to\", \"save\", \"tokenizer.json\"))\n",
    "'''\n",
    "tokenizer.save(Path(\"/Users/hapticslab/Programming/humusic/midi_generator/tokens/orchestra_token/tokenizer.json\"))\n",
    "'''\n",
    "#tokenizer.save(Path(\"C:/Users/keisu/Programming/humor/humusic/midi_generator/tokens/orchestra_token/tokenizer.json\"))\n",
    "#tokenizer.save(Path(\"C:/Users/keisu/Programming/humor/humusic/midi_generator/tokens/piano1_token/tokenizer.json\"))\n",
    "# And pushing it to the Hugging Face hub (you can download it back with .from_pretrained)\n",
    "#tokenizer.push_to_hub(\"username/model-name\", private=True, token=\"your_hf_token\")\n",
    "\n",
    "# Split MIDIs into smaller chunks for training\n",
    "dataset_chunks_dir = Path(\"/Users/hapticslab/Programming/humusic/midi_generator/midi_chunk/orchestra\")\n",
    "#dataset_chunks_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/midi_generator/midi_chunk/orchestra\")\n",
    "#dataset_chunks_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/midi_generator/midi_chunk/piano1_only\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Windows環境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Train the tokenizer with Byte Pair Encoding (BPE)\n",
    "#files_paths = list(Path(\"../datasets\").glob(\"**/*.mid\"))\n",
    "#dataset_dir = Path(\"/Users/hapticslab/Programming/humusic/datasets/piano1_only\")\n",
    "#dataset_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/datasets/orchestra\")\n",
    "dataset_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/datasets/piano1_only\")\n",
    "#dataset_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/datasets/maestro-v3.0.0\")\n",
    "files_paths = list(dataset_dir.glob(\"**/*.mid\"))\n",
    "\n",
    "\n",
    "#tokenizer.train(vocab_size=30000, files_paths=files_paths)\n",
    "\n",
    "\n",
    "#tokenizer.save(Path(\"path\", \"to\", \"save\", \"tokenizer.json\"))\n",
    "\n",
    "#tokenizer.save(Path(\"/Users/hapticslab/Programming/humusic/midi_generator/tokens/piano1_token/tokenizer.json\"))\n",
    "\n",
    "tokenizer.save(Path(\"C:/Users/keisu/Programming/humor/humusic/midi_generator/tokens/piano1_token/tokenizer.json\"))\n",
    "#tokenizer.save(Path(\"C:/Users/keisu/Programming/humor/humusic/midi_generator/tokens/maestro/tokenizer.json\"))\n",
    "# And pushing it to the Hugging Face hub (you can download it back with .from_pretrained)\n",
    "#tokenizer.push_to_hub(\"username/model-name\", private=True, token=\"your_hf_token\")\n",
    "\n",
    "# Split MIDIs into smaller chunks for training\n",
    "#dataset_chunks_dir = Path(\"/Users/hapticslab/Programming/humusic/midi_generator/midi_chunk/piano1_only\")\n",
    "dataset_chunks_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/midi_generator/midi_chunk/piano1_only\")\n",
    "#dataset_chunks_dir = Path(\"C:/Users/keisu/Programming/humor/humusic/midi_generator/midi_chunk/maestro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keisu\\AppData\\Roaming\\Python\\Python39\\site-packages\\miditok\\tokenizations\\remi.py:77: UserWarning: Attribute controls are not compatible with 'config.one_token_stream_for_programs' and multi-vocabulary tokenizers. Disabling them from the config.\n",
      "  super().__init__(tokenizer_config, params)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = REMI(params=Path(\"tokens/piano1_token/tokenizer.json\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### トークンをDataloaderに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "split_files_for_training(\n",
    "    files_paths=files_paths,\n",
    "    tokenizer=tokenizer,\n",
    "    save_dir=dataset_chunks_dir,\n",
    "    max_seq_len=1024,\n",
    ")\n",
    "'''\n",
    "\n",
    "\n",
    "# Create a Dataset, a DataLoader and a collator to train a model\n",
    "dataset = DatasetMIDI(\n",
    "    files_paths=list(dataset_chunks_dir.glob(\"**/*.mid\")),\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_len=1024,\n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    ")\n",
    "collator = DataCollator(tokenizer.pad_token_id, copy_inputs_as_labels=True)\n",
    "dataloader = DataLoader(dataset, batch_size=64, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention付きLSTMによる学習，生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# LSMT with Attention\n",
    "from LSTMwithAtt import LSTMwithAtt\n",
    "\n",
    "\n",
    "hidden_size = 200\n",
    "model = LSTMwithAtt(tokenizer, hidden_size)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=-100)\n",
    "\n",
    "num_epoch = 100\n",
    "\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 |: 100%|██████████| 8/8 [00:16<00:00,  2.09s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100 | loss 53.097999572753906 | time 16.68554973602295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.87s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/100 | loss 35.28253936767578 | time 14.983150005340576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.80s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/100 | loss 26.82324981689453 | time 14.419851541519165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/100 | loss 26.696746826171875 | time 14.463761568069458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.87s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/100 | loss 26.047178268432617 | time 14.942992448806763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.93s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/100 | loss 25.791162490844727 | time 15.418697357177734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/100 | loss 25.340930938720703 | time 14.725812673568726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.85s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8/100 | loss 24.937702178955078 | time 14.789016962051392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9/100 | loss 24.297531127929688 | time 14.484031915664673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/100 | loss 24.129179000854492 | time 14.179299592971802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.94s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11/100 | loss 23.262279510498047 | time 15.504584789276123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.92s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12/100 | loss 22.362049102783203 | time 15.340266466140747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13/100 | loss 22.00443458557129 | time 14.685998678207397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.81s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14/100 | loss 21.375980377197266 | time 14.50864577293396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.77s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15/100 | loss 21.00498390197754 | time 14.19074010848999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16/100 | loss 20.556867599487305 | time 14.74929428100586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17/100 | loss 20.42462921142578 | time 14.739850997924805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.89s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18/100 | loss 19.675508499145508 | time 15.091823101043701\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.85s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19/100 | loss 19.85062026977539 | time 14.811589479446411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.87s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20/100 | loss 19.29778289794922 | time 14.985620737075806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.94s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21/100 | loss 18.97947883605957 | time 15.513256549835205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.94s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22/100 | loss 17.945283889770508 | time 15.52844524383545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.91s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23/100 | loss 17.691177368164062 | time 15.311229705810547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.85s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24/100 | loss 16.94034194946289 | time 14.81178069114685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.90s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25/100 | loss 16.84226417541504 | time 15.230429410934448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.87s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26/100 | loss 16.689037322998047 | time 14.951366186141968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.90s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27/100 | loss 16.441593170166016 | time 15.206826448440552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 |: 100%|██████████| 8/8 [00:16<00:00,  2.00s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28/100 | loss 15.96037483215332 | time 16.01823878288269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.93s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29/100 | loss 15.828655242919922 | time 15.454419136047363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.85s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30/100 | loss 15.962679862976074 | time 14.78234577178955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.86s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31/100 | loss 15.65489387512207 | time 14.866543769836426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.88s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32/100 | loss 15.53884220123291 | time 15.062664031982422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.88s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33/100 | loss 15.232527732849121 | time 15.03161096572876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.90s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34/100 | loss 15.092109680175781 | time 15.172271728515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.91s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35/100 | loss 14.916648864746094 | time 15.279842376708984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.83s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36/100 | loss 15.013956069946289 | time 14.615631341934204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.90s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37/100 | loss 14.672782897949219 | time 15.194403409957886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 |: 100%|██████████| 8/8 [00:16<00:00,  2.05s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38/100 | loss 14.898781776428223 | time 16.400429010391235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 |: 100%|██████████| 8/8 [00:14<00:00,  1.84s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39/100 | loss 14.957802772521973 | time 14.760414123535156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.95s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40/100 | loss 15.05335521697998 | time 15.601012468338013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.91s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41/100 | loss 14.717511177062988 | time 15.29643702507019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 |: 100%|██████████| 8/8 [00:16<00:00,  2.05s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42/100 | loss 14.912382125854492 | time 16.414351224899292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 |: 100%|██████████| 8/8 [00:15<00:00,  1.96s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43/100 | loss 14.841286659240723 | time 15.671698093414307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 |:  38%|███▊      | 3/8 [00:05<00:09,  1.94s/batch]"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    i = 0\n",
    "    loss  = 0\n",
    "    \n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epoch} |', unit='batch'):\n",
    "        encoder_input = batch[\"input_ids\"][:,1:].to(device)\n",
    "        decoder_input = batch[\"input_ids\"][:,:-1].to(device)\n",
    "        labels = batch[\"input_ids\"][:,1:].to(device)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=tokenizer.vocab_size).float()\n",
    "        \n",
    "        out = model(encoder_input, decoder_input)\n",
    "        loss = criterion(out[0],labels_one_hot[0])\n",
    "        \n",
    "        for h in range(1,len(out)):\n",
    "            loss += criterion(out[h],labels_one_hot[h])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "    \n",
    "    print(f'epoch {epoch+1}/{num_epoch} | loss {loss} | time {time.time()-epoch_start_time}')\n",
    "    outfile = \"models/\" + \"lstmwithatt_\" + str(hidden_size) + \"_\" + dataset_name + \"_\" + str(epoch+1) + \".pt\"\n",
    "    torch.save(model.state_dict(),outfile)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 |: 100%|██████████| 8/8 [00:19<00:00,  2.39s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1/100 | loss 71.67308807373047 | time 19.12471103668213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.37s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2/100 | loss 70.7986068725586 | time 18.9780433177948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.35s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3/100 | loss 68.76653289794922 | time 18.804734706878662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 |: 100%|██████████| 8/8 [00:19<00:00,  2.39s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4/100 | loss 61.068626403808594 | time 19.14573645591736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 |: 100%|██████████| 8/8 [00:19<00:00,  2.41s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5/100 | loss 54.794654846191406 | time 19.259551525115967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.29s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6/100 | loss 50.6503791809082 | time 18.352508544921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7/100 | loss 47.3660888671875 | time 18.070428371429443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.35s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8/100 | loss 45.04960250854492 | time 18.799615621566772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9/100 | loss 43.98419952392578 | time 18.19895887374878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10/100 | loss 43.69457244873047 | time 18.481234788894653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 |: 100%|██████████| 8/8 [00:19<00:00,  2.45s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11/100 | loss 43.123958587646484 | time 19.595670700073242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12/100 | loss 42.31206512451172 | time 18.505943775177002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13/100 | loss 41.581153869628906 | time 18.4601149559021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.37s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14/100 | loss 40.6914176940918 | time 18.92789578437805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15/100 | loss 39.7229118347168 | time 18.438380241394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16/100 | loss 38.76359939575195 | time 18.439972162246704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17/100 | loss 37.83285903930664 | time 18.48227024078369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18/100 | loss 36.91071701049805 | time 18.07557725906372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.29s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19/100 | loss 35.95454788208008 | time 18.293341159820557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20/100 | loss 34.96541213989258 | time 17.91993260383606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21/100 | loss 33.93700408935547 | time 18.44291663169861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22/100 | loss 32.83905029296875 | time 18.095988988876343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23/100 | loss 31.755268096923828 | time 18.17275595664978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24/100 | loss 30.799394607543945 | time 18.210826635360718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25/100 | loss 29.95745849609375 | time 18.51432156562805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26/100 | loss 29.205224990844727 | time 18.399906158447266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27/100 | loss 28.505475997924805 | time 17.94415259361267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.33s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28/100 | loss 27.86959457397461 | time 18.6503586769104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.29s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29/100 | loss 27.346464157104492 | time 18.304810762405396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30/100 | loss 26.800310134887695 | time 17.9246084690094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.34s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31/100 | loss 26.23245620727539 | time 18.71366024017334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32/100 | loss 25.970794677734375 | time 18.21896004676819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33/100 | loss 25.66429901123047 | time 18.233699798583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34/100 | loss 25.478504180908203 | time 18.444890022277832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35/100 | loss 25.177947998046875 | time 18.281246423721313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36/100 | loss 24.88973045349121 | time 18.109646320343018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.25s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37/100 | loss 24.7061710357666 | time 18.014063119888306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38/100 | loss 24.543638229370117 | time 18.240792512893677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.32s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39/100 | loss 24.29388427734375 | time 18.531623363494873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40/100 | loss 24.02041244506836 | time 18.414289236068726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.32s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41/100 | loss 23.779375076293945 | time 18.571631908416748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42/100 | loss 23.569080352783203 | time 18.484516859054565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.29s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43/100 | loss 23.34670066833496 | time 18.35188937187195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.34s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44/100 | loss 23.209064483642578 | time 18.708815097808838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.33s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45/100 | loss 23.094009399414062 | time 18.682703733444214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.34s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46/100 | loss 22.98200035095215 | time 18.697852611541748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47/100 | loss 22.801498413085938 | time 18.190155744552612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.32s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48/100 | loss 22.833206176757812 | time 18.568655967712402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49/100 | loss 22.599960327148438 | time 18.410383939743042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50/100 | loss 22.45964241027832 | time 17.899072647094727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.32s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51/100 | loss 22.31334686279297 | time 18.58606719970703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.25s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52/100 | loss 22.14278793334961 | time 18.042356967926025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53/100 | loss 22.077226638793945 | time 18.098283767700195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54/100 | loss 21.919111251831055 | time 18.220266580581665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55/100 | loss 21.87679672241211 | time 18.24171233177185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.35s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56/100 | loss 21.75187110900879 | time 18.79324460029602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57/100 | loss 21.706209182739258 | time 18.481658220291138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58/100 | loss 21.57791519165039 | time 18.389821767807007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59/100 | loss 21.545486450195312 | time 18.079971313476562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60/100 | loss 21.456073760986328 | time 18.167425870895386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61/100 | loss 21.423851013183594 | time 18.42743945121765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62/100 | loss 21.343372344970703 | time 18.16793727874756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63/100 | loss 21.258689880371094 | time 18.235328912734985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.25s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64/100 | loss 21.22774887084961 | time 17.985283136367798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65/100 | loss 21.20960235595703 | time 18.4124596118927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 66/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66/100 | loss 21.13492202758789 | time 18.252376079559326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 67/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.25s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67/100 | loss 21.025362014770508 | time 18.0187087059021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 68/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.32s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68/100 | loss 20.976760864257812 | time 18.58318018913269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 69/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69/100 | loss 20.890605926513672 | time 18.13117003440857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 70/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70/100 | loss 20.86811065673828 | time 17.933352947235107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 71/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71/100 | loss 20.727327346801758 | time 18.515994548797607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 72/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.29s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72/100 | loss 20.677858352661133 | time 18.30551052093506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 73/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73/100 | loss 20.60679054260254 | time 17.929510593414307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 74/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.29s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74/100 | loss 20.58609962463379 | time 18.319668292999268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 75/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75/100 | loss 20.51468849182129 | time 18.40676236152649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 76/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76/100 | loss 20.377050399780273 | time 18.206313610076904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 77/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77/100 | loss 20.377155303955078 | time 18.063209533691406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 78/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.33s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78/100 | loss 20.244388580322266 | time 18.60857582092285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 79/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79/100 | loss 20.22287368774414 | time 18.47366452217102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 80/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.25s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80/100 | loss 20.106945037841797 | time 17.979169368743896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 81/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81/100 | loss 20.117223739624023 | time 18.255573749542236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 82/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.31s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82/100 | loss 20.017183303833008 | time 18.477583169937134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 83/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83/100 | loss 19.947681427001953 | time 17.945003509521484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 84/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84/100 | loss 19.907743453979492 | time 17.90779447555542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 85/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85/100 | loss 19.833833694458008 | time 18.42211389541626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 86/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86/100 | loss 19.82773780822754 | time 18.1512393951416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 87/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.21s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87/100 | loss 19.619853973388672 | time 17.64326572418213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 88/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.34s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88/100 | loss 19.471363067626953 | time 18.7345027923584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 89/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89/100 | loss 19.349349975585938 | time 18.224059104919434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 90/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90/100 | loss 19.25105094909668 | time 17.90454626083374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 91/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.28s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91/100 | loss 19.20840072631836 | time 18.227272510528564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 92/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92/100 | loss 19.08904266357422 | time 18.118288278579712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 93/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93/100 | loss 19.065185546875 | time 18.078261137008667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 94/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.24s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94/100 | loss 18.989439010620117 | time 17.947097778320312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 95/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.30s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95/100 | loss 18.95599937438965 | time 18.393491506576538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 96/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96/100 | loss 18.89863395690918 | time 18.12728261947632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 97/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.22s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97/100 | loss 18.885889053344727 | time 17.795225143432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 98/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.26s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98/100 | loss 18.83961296081543 | time 18.11105489730835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 99/100 |: 100%|██████████| 8/8 [00:18<00:00,  2.27s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99/100 | loss 18.714792251586914 | time 18.197400093078613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 100/100 |: 100%|██████████| 8/8 [00:17<00:00,  2.25s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100/100 | loss 18.58608627319336 | time 17.968130826950073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#masked input\n",
    "\n",
    "model.train()\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    epoch_start_time = time.time()\n",
    "    i = 0\n",
    "    loss  = 0\n",
    "    \n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epoch} |', unit='batch'):\n",
    "        inputs_shape = batch[\"input_ids\"].shape  # トークンID列    \n",
    "        mask_border_index = inputs_shape[1]//4\n",
    "        masked_inputs = batch[\"input_ids\"][:,1:].clone().to(device)\n",
    "        masked_inputs[:,mask_border_index:] = tokenizer.pad_token_id  # マスクされた入力\n",
    "        \n",
    "        #encoder_input = batch[\"input_ids\"][:,1:].to(device)\n",
    "        decoder_input = batch[\"input_ids\"][:,:-1].to(device)\n",
    "        labels = batch[\"input_ids\"][:,1:].to(device)\n",
    "        labels_one_hot = F.one_hot(labels, num_classes=tokenizer.vocab_size).float()\n",
    "        \n",
    "        out = model(masked_inputs, decoder_input)\n",
    "        loss = criterion(out[0],labels_one_hot[0])\n",
    "        \n",
    "        for h in range(1,len(out)):\n",
    "            loss += criterion(out[h],labels_one_hot[h])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        i += 1\n",
    "    \n",
    "    print(f'epoch {epoch+1}/{num_epoch} | loss {loss} | time {time.time()-epoch_start_time}')\n",
    "    outfile = \"models/\" + \"lstmwithatt_\" + \"maskedinput_\" + str(hidden_size) + \"_\" + dataset_name + \"_\" + str(epoch+1) + \".pt\"\n",
    "    torch.save(model.state_dict(),outfile)  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成-プロンプトのトークン化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 7091]),\n",
       " tensor([[  4, 173, 280,  ...,  46, 102, 140]], device='cuda:0'))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 入力トークン列の例\n",
    "prompt = (\"prompt/bach_850.mid\")\n",
    "\n",
    "input_ids = torch.tensor([tokenizer(prompt)]).to(device)\n",
    "input_ids.shape, input_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[280, 280, 280, 280, 280, 110, 280, 280, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 104, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110, 280, 280, 104, 110]\n"
     ]
    }
   ],
   "source": [
    "# Generate a MIDI file\n",
    "\n",
    "#model.load_state_dict(torch.load(\"models/ltest30.model\"))\n",
    "\n",
    "#torch.set_printoptions(threshold=torch.inf)\n",
    "model.eval()\n",
    "\n",
    "gen_token = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    #prompt_input = torch.LongTensor( input_ids ).to(device)\n",
    "    #print(input_ids.shape)\n",
    "    x = model.input_emb(input_ids)\n",
    "    #print(x.shape)\n",
    "    ox, (hnx, cnx) = model.lstm1(x)\n",
    "    #print(ox.shape, hnx.shape,cnx.shape)\n",
    "    hnx, cnx = hnx[:,0,:], cnx[:,0,:]\n",
    "    \n",
    "    wid = input_ids[0][0]\n",
    "    \n",
    "    sl = 0\n",
    "    while True:\n",
    "        wids = torch.LongTensor([wid]).to(device)\n",
    "        y = model.answer_emb(wids)\n",
    "        #print(y.shape)\n",
    "        \n",
    "        oy, (hnx, cnx) = model.lstm2(y, (hnx, cnx))\n",
    "        oy = oy.unsqueeze(1)\n",
    "        ox1 = ox.permute(0,2,1)\n",
    "        sim = torch.bmm(oy,ox1)\n",
    "        bs, yws, xws = sim.shape\n",
    "        sim2 = sim.reshape(bs*yws,xws)\n",
    "        alpha = F.softmax(sim2,dim=1).reshape(bs, yws, xws)\n",
    "        ct = torch.bmm(alpha,ox)\n",
    "        oy1 = torch.cat([ct,oy],dim=2)\n",
    "        oy2 = model.Wc(oy1)\n",
    "        oy3 = model.W(oy2)\n",
    "        wid = torch.argmax(oy3[0]).item()\n",
    "        gen_token.append(wid)\n",
    "        #if (wid == esid):\n",
    "            #break\n",
    "        if (sl == 2000):\n",
    "            break\n",
    "        sl += 1\n",
    "    print(gen_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated MIDI Tokens: Score(ttype=Tick, tpq=8, begin=0, end=0, tracks=0, notes=0, time_sig=1, key_sig=0, markers=0)\n",
      "generated_test_1734259681.766107.mid\n"
     ]
    }
   ],
   "source": [
    "generated = tokenizer.decode(gen_token)\n",
    "print(\"Generated MIDI Tokens:\", generated)\n",
    "generated_time = str(time.time())\n",
    "\n",
    "generated.dump_midi(\"generated_test_\"+ generated_time +\".mid\")\n",
    "print(\"generated_test_\"+ generated_time +\".mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trasformerによる学習，生成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Config, GPT2LMHeadModel\n",
    "\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=tokenizer.vocab_size,\n",
    "    n_positions=1024,\n",
    "    n_ctx=1024,\n",
    "    n_embd=256,\n",
    "    n_layer=4,\n",
    "    n_head=4,\n",
    "    \n",
    "    bos_token_id=tokenizer[\"BOS_None\"],\n",
    "    eos_token_id=tokenizer[\"EOS_None\"],\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    "    \n",
    "    )\n",
    "\n",
    "model = GPT2LMHeadModel(config).to(device)\n",
    "\n",
    "# 損失関数とオプティマイザ\n",
    "criterion = torch.nn.CrossEntropyLoss()  # トークンの予測タスクに使う\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)  # 適切な学習率を設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/300: 100%|██████████| 29/29 [00:15<00:00,  1.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300 - Loss: 4.4964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/300: 100%|██████████| 29/29 [00:15<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/300 - Loss: 4.4984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/300: 100%|██████████| 29/29 [00:15<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/300 - Loss: 4.4974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/300:  24%|██▍       | 7/29 [00:03<00:12,  1.76it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()  \u001b[38;5;66;03m# モデルを学習モードに切り替え\u001b[39;00m\n\u001b[0;32m      8\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(dataloader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''inputs_shape = batch[\"input_ids\"].shape  # トークンID列    \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    labels = batch[\"labels\"][:,:-1].to(device)    # 正解ラベル'''\u001b[39;00m\n\u001b[0;32m     20\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# マスク（任意）\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\miditok\\pytorch_data\\datasets.py:226\u001b[0m, in \u001b[0;36mDatasetMIDI.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    223\u001b[0m         item[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels_key_name] \u001b[38;5;241m=\u001b[39m labels\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item\n\u001b[1;32m--> 226\u001b[0m tseq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;66;03m# If not one_token_stream, we only take the first track/sequence\u001b[39;00m\n\u001b[0;32m    228\u001b[0m token_ids \u001b[38;5;241m=\u001b[39m tseq\u001b[38;5;241m.\u001b[39mids \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mone_token_stream \u001b[38;5;28;01melse\u001b[39;00m tseq[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mids\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\miditok\\pytorch_data\\datasets.py:256\u001b[0m, in \u001b[0;36mDatasetMIDI._tokenize_score\u001b[1;34m(self, score)\u001b[0m\n\u001b[0;32m    248\u001b[0m     ac_indexes \u001b[38;5;241m=\u001b[39m create_random_ac_indexes(\n\u001b[0;32m    249\u001b[0m         score,\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mattribute_controls,\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracks_idx_random_ratio_range,\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbars_idx_random_ratio_range,\n\u001b[0;32m    253\u001b[0m     )\n\u001b[0;32m    255\u001b[0m \u001b[38;5;66;03m# Tokenize it\u001b[39;00m\n\u001b[1;32m--> 256\u001b[0m tokseq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mno_preprocess_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattribute_controls_indexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mac_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    260\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m# If tokenizing on the fly a multi-stream tokenizer, only keeps the first track\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_tokenize \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mone_token_stream:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\miditok\\midi_tokenizer.py:1658\u001b[0m, in \u001b[0;36mMusicTokenizer.encode\u001b[1;34m(self, score, encode_ids, no_preprocess_score, attribute_controls_indexes)\u001b[0m\n\u001b[0;32m   1655\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess_score(score)\n\u001b[0;32m   1657\u001b[0m \u001b[38;5;66;03m# Tokenize it\u001b[39;00m\n\u001b[1;32m-> 1658\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score_to_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattribute_controls_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1659\u001b[0m \u001b[38;5;66;03m# Add bar/beat ticks here to TokSeq as they need to be from preprocessed Score\u001b[39;00m\n\u001b[0;32m   1660\u001b[0m add_bar_beats_ticks_to_tokseq(tokens, score)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\miditok\\midi_tokenizer.py:1179\u001b[0m, in \u001b[0;36mMusicTokenizer._score_to_tokens\u001b[1;34m(self, score, attribute_controls_indexes)\u001b[0m\n\u001b[0;32m   1177\u001b[0m ticks_beats \u001b[38;5;241m=\u001b[39m get_beats_ticks(score, only_notes_onsets\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ti, track \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(score\u001b[38;5;241m.\u001b[39mtracks):\n\u001b[1;32m-> 1179\u001b[0m     track_events \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_track_events\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticks_per_beat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mticks_per_quarter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticks_bars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticks_beats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattribute_controls_indexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1187\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mone_token_stream_for_programs:\n\u001b[0;32m   1188\u001b[0m         all_events \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m track_events\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\miditok\\midi_tokenizer.py:1360\u001b[0m, in \u001b[0;36mMusicTokenizer._create_track_events\u001b[1;34m(self, track, ticks_per_beat, time_division, ticks_bars, ticks_beats, attribute_controls_indexes)\u001b[0m\n\u001b[0;32m   1356\u001b[0m \u001b[38;5;66;03m# Control changes (in the future, and handle pedals redundancy)\u001b[39;00m\n\u001b[0;32m   1357\u001b[0m \n\u001b[0;32m   1358\u001b[0m \u001b[38;5;66;03m# Add chords\u001b[39;00m\n\u001b[0;32m   1359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_chords \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m track\u001b[38;5;241m.\u001b[39mis_drum:\n\u001b[1;32m-> 1360\u001b[0m     chords \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_chords\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrack\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticks_per_beat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchord_maps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchord_maps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogram\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogram\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspecify_root_note\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchord_tokens_with_root_note\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeat_res\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_first_beat_res\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1367\u001b[0m \u001b[43m        \u001b[49m\u001b[43munknown_chords_num_notes_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchord_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1369\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chord \u001b[38;5;129;01min\u001b[39;00m chords:\n\u001b[0;32m   1370\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_programs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mprogram_changes:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\miditok\\utils\\utils.py:272\u001b[0m, in \u001b[0;36mdetect_chords\u001b[1;34m(notes, ticks_per_beat, chord_maps, program, specify_root_note, beat_res, onset_offset, unknown_chords_num_notes_range, simul_notes_limit)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;66;03m# Selects the possible chords notes\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m notes[count, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m notes[count, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tpb_half:\n\u001b[1;32m--> 272\u001b[0m     onset_notes \u001b[38;5;241m=\u001b[39m \u001b[43monset_notes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43monset_notes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43monset_notes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    273\u001b[0m chord \u001b[38;5;241m=\u001b[39m onset_notes[np\u001b[38;5;241m.\u001b[39mwhere(onset_notes[:, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m onset_notes[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m tpb_half)]\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# Creates the \"chord map\" and see if it has a \"known\" quality, append a chord\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# event if it is valid\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m現在のセルまたは前のセルでコードを実行中に、カーネル (Kernel) がクラッシュしました。\n",
      "\u001b[1;31mエラーの原因を特定するには、セル内のコードを確認してください。\n",
      "\u001b[1;31m詳細については<a href='https://aka.ms/vscodeJupyterKernelCrash'>こちら</a>をクリックします。\n",
      "\u001b[1;31m詳細については、Jupyter <a href='command:jupyter.viewOutput'>ログ</a> を参照してください。"
     ]
    }
   ],
   "source": [
    "torch.set_printoptions(edgeitems=torch.inf)\n",
    "\n",
    "# 学習ループ\n",
    "epochs = 300 # エポック数\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # モデルを学習モードに切り替え\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
    "        inputs_shape = batch[\"input_ids\"].shape  # トークンID列    \n",
    "        \n",
    "        \n",
    "        mask_border_index = inputs_shape[1]//4\n",
    "        masked_inputs = batch[\"input_ids\"][:,1:].clone().to(device)\n",
    "        masked_inputs[:,mask_border_index:] = tokenizer.pad_token_id  # マスクされた入力\n",
    "        \n",
    "        \n",
    "        labels = batch[\"labels\"][:,:-1].to(device)    # 正解ラベル\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)  # マスク（任意）\n",
    "        \n",
    "        \n",
    "        \n",
    "        #print(inputs[0],labels[0])\n",
    "        \n",
    "        # 勾配を初期化\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # モデルの前方計算\n",
    "        outputs = model(\n",
    "            input_ids=inputs,\n",
    "            labels=labels,\n",
    "            attention_mask=attention_mask,\n",
    "        )\n",
    "        loss = outputs.loss  # GPT2LMHeadModelは自動で損失を計算する\n",
    "\n",
    "        # 勾配の計算とパラメータの更新\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 損失を記録\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "\n",
    "    # エポックごとの平均損失を出力\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    #model.save_pretrained(\"models/transformer/\" + \"piano1_only/test\" + str(epoch+1) + \".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epoch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/transformer/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpiano1_only/shifted_test\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mepoch\u001b[49m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epoch' is not defined"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"models/transformer/\" + \"piano1_only/shifted_test\" + str(epoch+1) + \".pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成-プロンプトのトークン化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4, 175, 280,   9, 102, 109, 176, 280,  32, 102, 114, 182, 280,  28,\n",
       "         102, 109, 183, 280,  33, 102, 110, 185, 280,  32, 102, 112, 189, 280,\n",
       "          28, 102, 109, 191, 280,  35, 102, 109, 192, 280,  40, 102, 110, 194,\n",
       "         280,  39, 102, 112, 198, 280,  38, 102, 116,   4, 175, 280,  29, 102,\n",
       "         109, 176, 280,  41, 102, 114, 182, 280,  36, 102, 109, 183, 280,  17,\n",
       "         102, 109, 184, 280,  41, 102, 115, 191, 280,  36, 102, 109, 192, 280,\n",
       "          39, 102, 117]], device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 入力トークン列の例\n",
    "prompt = (\"prompt/output.mid\")\n",
    "\n",
    "input_ids = torch.tensor([tokenizer(prompt)]).to(device)\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  4, 175, 280,   9, 102, 109, 176, 280,  32, 102, 114, 182, 280,  28,\n",
      "         102, 109, 183, 280,  33, 102, 110, 185, 280,  32, 102, 112, 189, 280,\n",
      "          28, 102, 109, 191, 280,  35, 102, 109, 192, 280,  40, 102, 110, 194,\n",
      "         280,  39, 102, 112, 198, 280,  38, 102, 116,   4, 175, 280,  29, 102,\n",
      "         109, 176, 280,  41, 102, 114, 182, 280,  36, 102, 109, 183, 280,  17,\n",
      "         102, 109, 184, 280,  41, 102, 115, 191, 280,  36, 102, 109, 192, 280,\n",
      "          39, 102, 117,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0]], device='cuda:0')\n",
      "torch.Size([1, 1023])\n"
     ]
    }
   ],
   "source": [
    "#ぱっでぃんぐは不要でした\n",
    "\n",
    "# 1次元で50要素を持つベクトル\n",
    "vector = input_ids\n",
    "\n",
    "# 1024要素に拡張するためのパディング\n",
    "target_length = 1023\n",
    "padding_length = target_length - input_ids.size(1)\n",
    "\n",
    "# 末尾にパディングを追加\n",
    "padded_vector = F.pad(input_ids, (0, padding_length), value=0)  # value=0 はパディングの値\n",
    "\n",
    "print(padded_vector)\n",
    "print(padded_vector.size())  # torch.Size([1024])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成-メインプロセス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\keisu\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `1.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\keisu\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\generation\\configuration_utils.py:520: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#regenerate\n",
    "\n",
    "# モデルの読み込み\n",
    "model = GPT2LMHeadModel.from_pretrained(\"models/transformer/piano1_only/shifted_test27.pt\")\n",
    "#model = GPT2LMHeadModel.from_pretrained(\"models/transformer/\" + \"piano1_only/shifted_test\" + \"26\" + \".pt\")\n",
    "#C:\\Users\\keisu\\Programming\\humor\\humusic\\midi_generator\\models\\transformer\\piano1_only\\shifted_test27.pt\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# モデルによる生成\n",
    "# output = model.generate(\n",
    "#     input_ids=input_ids,\n",
    "#     max_length=1024,\n",
    "#     num_beams=5,\n",
    "#     no_repeat_ngram_size=2,\n",
    "# )\n",
    "\n",
    "# モデルによる生成\n",
    "with torch.no_grad():\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids,\n",
    "        max_length=1024,\n",
    "        num_beams=5,  # ビームサーチ\n",
    "        no_repeat_ngram_size=2,  # 同じn-gramを繰り返さない\n",
    "        temperature=1.2,  # サンプリングの多様性を調整\n",
    "        top_k=50,  # 上位k個のトークンをサンプリング\n",
    "        top_p=0.95,  # 累積確率cutoff\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成-結果をdetokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated MIDI Tokens: Score(ttype=Tick, tpq=8, begin=0, end=1368, tracks=1, notes=49, time_sig=1, key_sig=0, markers=0)\n"
     ]
    }
   ],
   "source": [
    "# トークン列をデコードして結果を表示\n",
    "generated = tokenizer.decode(output[0].tolist())\n",
    "print(\"Generated MIDI Tokens:\", generated)\n",
    "\n",
    "generated.dump_midi(\"maskedinput_transformer_shifted_10_5_pad.mid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## python(GPU)のキャッシュクリア"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, dataset, dataloader, collator\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成したmidiの再生\n",
    "強制終了するとipykernelがクラッシュするので注意"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pygameによる再生\n",
    "\n",
    "file_name = Path(\"generated_test_\"+ generated_time +\".mid\")\n",
    "\n",
    "import time\n",
    "import pygame\n",
    "\n",
    "# Initialize pygame\n",
    "pygame.init()\n",
    "\n",
    "# Set up the mixer\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Load the MIDI file\n",
    "#pygame.mixer.music.load('bach_850.mid')\n",
    "pygame.mixer.music.load(file_name)\n",
    "#pygame.mixer.music.load('test.mid')\n",
    "\n",
    "# Play the MIDI file\n",
    "pygame.mixer.music.set_volume(0.25)\n",
    "pygame.mixer.music.play()\n",
    "\n",
    "\n",
    "# Keep the program running until the music stops\n",
    "while pygame.mixer.music.get_busy():\n",
    "    if input(\"Press 'q' to quit: \") == 'q':\n",
    "        break\n",
    "    pygame.time.Clock().tick(10)\n",
    "\n",
    "# Quit pygame\n",
    "pygame.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prompt.midの作成セル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まずは1小節のnote（ド、C4）を1つ生成してみる\n",
    "import mido\n",
    "from mido import Message, MidiFile, MidiTrack, MetaMessage\n",
    "\n",
    "mid = MidiFile()\n",
    "track = MidiTrack()\n",
    "mid.tracks.append(track)\n",
    "track.append(MetaMessage('set_tempo', tempo=mido.bpm2tempo(120))) # bpm120\n",
    "\n",
    "track.append(Message('note_on', note=74, velocity=57, time=120))\n",
    "track.append(Message('note_on', note=76, velocity=57, time=120))\n",
    "track.append(Message('note_off', note=74, velocity=0, time=20))\n",
    "track.append(Message('note_on', note=78, velocity=57, time=100))\n",
    "track.append(Message('note_off', note=76, velocity=0, time=20))\n",
    "track.append(Message('note_on', note=69, velocity=60, time=100))\n",
    "track.append(Message('note_off', note=78, velocity=0, time=20))\n",
    "track.append(Message('note_off', note=69, velocity=0, time=100))\n",
    "track.append(Message('note_on', note=78, velocity=57, time=0))\n",
    "track.append(Message('note_on', note=76, velocity=57, time=120))\n",
    "track.append(Message('note_off', note=78, velocity=0, time=20))\n",
    "track.append(Message('note_on', note=74, velocity=57, time=100))\n",
    "track.append(Message('note_off', note=76, velocity=0, time=20))\n",
    "track.append(Message('note_on', note=81, velocity=62, time=100))\n",
    "track.append(Message('note_off', note=74, velocity=0, time=20))\n",
    "track.append(Message('note_off', note=81, velocity=0, time=100))\n",
    "track.append(Message('note_on', note=74, velocity=58, time=0))\n",
    "track.append(Message('note_on', note=76, velocity=58, time=120))\n",
    "track.append(Message('note_off', note=74, velocity=0, time=20))\n",
    "track.append(Message('note_on', note=78, velocity=58, time=100))\n",
    "track.append(Message('note_off', note=76, velocity=0, time=20))\n",
    "track.append(Message('note_on', note=69, velocity=61, time=100))\n",
    "track.append(Message('note_off', note=78, velocity=0, time=20))\n",
    "track.append(Message('note_off', note=69, velocity=0, time=100))\n",
    "track.append(Message('note_on', note=78, velocity=57, time=0))\n",
    "track.append(Message('note_on', note=76, velocity=57, time=120))\n",
    "track.append(Message('note_off', note=78, velocity=0, time=20))\n",
    "track.append(Message('note_on', note=74, velocity=57, time=100))\n",
    "track.append(Message('note_off', note=76, velocity=0, time=20))\n",
    "track.append(Message('note_on', note=79, velocity=60, time=100))\n",
    "track.append(Message('note_off', note=74, velocity=0, time=20))\n",
    "\n",
    "\n",
    "mid.save('prompt.mid') # MidiFileを保存\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
